{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-02T20:38:45.505023Z",
     "iopub.status.busy": "2025-02-02T20:38:45.504756Z",
     "iopub.status.idle": "2025-02-02T20:38:54.602159Z",
     "shell.execute_reply": "2025-02-02T20:38:54.601174Z",
     "shell.execute_reply.started": "2025-02-02T20:38:45.504996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.36.1)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Collecting wordninja\n",
      "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting levenshtein\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from levenshtein)\n",
      "  Downloading rapidfuzz-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
      "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541530 sha256=7c4f31a6bd839a729c6b1ce5d546d45c7ef41ad8c0d1b72e7e13361c32b92fd7\n",
      "  Stored in directory: /root/.cache/pip/wheels/aa/44/3a/f2a5c1859b8b541ded969b4cd12d0a58897f12408f4f51e084\n",
      "Successfully built wordninja\n",
      "Installing collected packages: wordninja, rapidfuzz, levenshtein, python-Levenshtein\n",
      "Successfully installed levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.12.1 wordninja-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# open this to install all the required packages\n",
    "#!pip install opencv-python matplotlib imageio gdown tensorflow wordninja python-Levenshtein levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:38:54.603221Z",
     "iopub.status.busy": "2025-02-02T20:38:54.602979Z",
     "iopub.status.idle": "2025-02-02T20:39:06.986547Z",
     "shell.execute_reply": "2025-02-02T20:39:06.985905Z",
     "shell.execute_reply.started": "2025-02-02T20:38:54.603201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "import gdown\n",
    "import zipfile\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler ,ModelCheckpoint ,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, TimeDistributed, Flatten, Input\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use GPu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:06.988502Z",
     "iopub.status.busy": "2025-02-02T20:39:06.987961Z",
     "iopub.status.idle": "2025-02-02T20:39:07.649586Z",
     "shell.execute_reply": "2025-02-02T20:39:07.648606Z",
     "shell.execute_reply.started": "2025-02-02T20:39:06.988477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU is available!\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU: {gpu}\")\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:07.651710Z",
     "iopub.status.busy": "2025-02-02T20:39:07.651356Z",
     "iopub.status.idle": "2025-02-02T20:39:07.709028Z",
     "shell.execute_reply": "2025-02-02T20:39:07.708119Z",
     "shell.execute_reply.started": "2025-02-02T20:39:07.651675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# print(f\"Available GPUs: {gpus}\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:07.710297Z",
     "iopub.status.busy": "2025-02-02T20:39:07.709956Z",
     "iopub.status.idle": "2025-02-02T20:39:07.721079Z",
     "shell.execute_reply": "2025-02-02T20:39:07.720307Z",
     "shell.execute_reply.started": "2025-02-02T20:39:07.710272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:07.722312Z",
     "iopub.status.busy": "2025-02-02T20:39:07.722006Z",
     "iopub.status.idle": "2025-02-02T20:39:07.733709Z",
     "shell.execute_reply": "2025-02-02T20:39:07.732817Z",
     "shell.execute_reply.started": "2025-02-02T20:39:07.722282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \n",
    "tf.get_logger().setLevel(\"ERROR\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. download and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:07.734848Z",
     "iopub.status.busy": "2025-02-02T20:39:07.734538Z",
     "iopub.status.idle": "2025-02-02T20:39:17.529150Z",
     "shell.execute_reply": "2025-02-02T20:39:17.528242Z",
     "shell.execute_reply.started": "2025-02-02T20:39:07.734819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\n",
      "From (redirected): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL&confirm=t&uuid=f64715b7-ffd3-40b9-b953-11c8ada901dd\n",
      "To: /kaggle/working/lip_data.zip\n",
      "100%|██████████| 423M/423M [00:03<00:00, 140MB/s]  \n"
     ]
    }
   ],
   "source": [
    "dataset_url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "output_file = 'lip_data.zip'\n",
    "gdown.download(dataset_url, output_file, quiet=False)\n",
    "with zipfile.ZipFile(output_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall('lip_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.532174Z",
     "iopub.status.busy": "2025-02-02T20:39:17.531947Z",
     "iopub.status.idle": "2025-02-02T20:39:17.858980Z",
     "shell.execute_reply": "2025-02-02T20:39:17.858181Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.532156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 40\n"
     ]
    }
   ],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "char_to_index = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "print(f\"Vocabulary size: {char_to_index.vocabulary_size()}\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_index.get_vocabulary(),\n",
    "    invert=True, \n",
    "    oov_token=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.861004Z",
     "iopub.status.busy": "2025-02-02T20:39:17.860709Z",
     "iopub.status.idle": "2025-02-02T20:39:17.868123Z",
     "shell.execute_reply": "2025-02-02T20:39:17.867120Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.860978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_mouth_region(video_path: str) -> np.ndarray:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        mouth_region = gray_frame[180:240, 80:220]\n",
    "        frames.append(mouth_region)\n",
    "    cap.release()\n",
    "    # print(frames)\n",
    "    \n",
    "    if len(frames)>75 :\n",
    "        frames = frames[:75]\n",
    "    else:\n",
    "        frames.extend([frames[-1]] * (75-len(frames)))\n",
    "    frames = np.array(frames, dtype=np.float32)\n",
    "    frames = (frames-np.mean(frames)) / np.std(frames)\n",
    "    # print(frames)\n",
    "    # print(\"------------------------sam--------------\")\n",
    "    # print(len(frames))\n",
    "    return np.expand_dims(frames, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.869160Z",
     "iopub.status.busy": "2025-02-02T20:39:17.868881Z",
     "iopub.status.idle": "2025-02-02T20:39:17.881351Z",
     "shell.execute_reply": "2025-02-02T20:39:17.880498Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.869132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_transcription(transcription_path: str) ->  tf.Tensor:\n",
    "\n",
    "    with open(transcription_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if parts[2] != 'sil':  \n",
    "            tokens.extend(list(parts[2]))  \n",
    "    return char_to_index(tf.constant(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.882422Z",
     "iopub.status.busy": "2025-02-02T20:39:17.882148Z",
     "iopub.status.idle": "2025-02-02T20:39:17.893082Z",
     "shell.execute_reply": "2025-02-02T20:39:17.892131Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.882398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_lip_data_with_augmentation(file_path: str):\n",
    "    file_path = bytes.decode(file_path.numpy())\n",
    "    file_name = file_path.split('/')[-1].split('.')[0] \n",
    "    video_file = os.path.join('/kaggle/working/lip_data/data/s1', f'{file_name}.mpg')\n",
    "    transcription_file = os.path.join('/kaggle/working/lip_data/data/alignments/s1', f'{file_name}.align')\n",
    "    video_frames = extract_mouth_region(video_file)\n",
    "    transcription = load_transcription(transcription_file)\n",
    "    # print(file_path)\n",
    "    # print(\"-----------------------\")\n",
    "    # print(file_name)\n",
    "    # print(\"------------------------\")\n",
    "    # print(len(video_frames))\n",
    "\n",
    "    if np.random.rand()>0.5:\n",
    "        video_frames = np.flip(video_frames, axis=2)  \n",
    "    return video_frames, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.894119Z",
     "iopub.status.busy": "2025-02-02T20:39:17.893842Z",
     "iopub.status.idle": "2025-02-02T20:39:17.909228Z",
     "shell.execute_reply": "2025-02-02T20:39:17.908395Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.894094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def map_data_with_augmentation(file_path: str):\n",
    "    result = tf.py_function(load_lip_data_with_augmentation, [file_path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:17.910375Z",
     "iopub.status.busy": "2025-02-02T20:39:17.910118Z",
     "iopub.status.idle": "2025-02-02T20:39:18.003534Z",
     "shell.execute_reply": "2025-02-02T20:39:18.002824Z",
     "shell.execute_reply.started": "2025-02-02T20:39:17.910351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lip_dataset = tf.data.Dataset.list_files('/kaggle/working/lip_data/data/s1/*.mpg', shuffle=False)\n",
    "lip_dataset = lip_dataset.shuffle(500, reshuffle_each_iteration=False)\n",
    "lip_dataset = lip_dataset.map(map_data_with_augmentation)\n",
    "lip_dataset = lip_dataset.padded_batch(2, padded_shapes=([75, 60, 140, 1], [40]))\n",
    "lip_dataset = lip_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.004629Z",
     "iopub.status.busy": "2025-02-02T20:39:18.004367Z",
     "iopub.status.idle": "2025-02-02T20:39:18.009630Z",
     "shell.execute_reply": "2025-02-02T20:39:18.008694Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.004605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 75, 60, 140, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(lip_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.010739Z",
     "iopub.status.busy": "2025-02-02T20:39:18.010486Z",
     "iopub.status.idle": "2025-02-02T20:39:18.064015Z",
     "shell.execute_reply": "2025-02-02T20:39:18.063240Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.010715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = lip_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.065032Z",
     "iopub.status.busy": "2025-02-02T20:39:18.064763Z",
     "iopub.status.idle": "2025-02-02T20:39:18.282614Z",
     "shell.execute_reply": "2025-02-02T20:39:18.281703Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.065000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val = sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.284049Z",
     "iopub.status.busy": "2025-02-02T20:39:18.283707Z",
     "iopub.status.idle": "2025-02-02T20:39:18.634885Z",
     "shell.execute_reply": "2025-02-02T20:39:18.634126Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.284009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ed44a9e28f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val[0][1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.635907Z",
     "iopub.status.busy": "2025-02-02T20:39:18.635683Z",
     "iopub.status.idle": "2025-02-02T20:39:18.680809Z",
     "shell.execute_reply": "2025-02-02T20:39:18.679903Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.635885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous decoded text: binblueinrsevensoon\n",
      "Segmented text: bin blue in r seven soon\n"
     ]
    }
   ],
   "source": [
    "decoded_continuous = tf.strings.reduce_join(\n",
    "    [num_to_char(token) for token in val[1][0]],\n",
    "    separator='' \n",
    ").numpy().decode('utf-8')\n",
    "\n",
    "print(\"Continuous decoded text:\", decoded_continuous)\n",
    "segmented_words = wordninja.split(decoded_continuous)\n",
    "decoded_text_with_spaces = ' '.join(segmented_words)\n",
    "\n",
    "print(\"Segmented text:\", decoded_text_with_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.682012Z",
     "iopub.status.busy": "2025-02-02T20:39:18.681760Z",
     "iopub.status.idle": "2025-02-02T20:39:18.695509Z",
     "shell.execute_reply": "2025-02-02T20:39:18.694674Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.681981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_data = lip_dataset.take(350)\n",
    "test_data = lip_dataset.skip(300).take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.696535Z",
     "iopub.status.busy": "2025-02-02T20:39:18.696347Z",
     "iopub.status.idle": "2025-02-02T20:39:18.701827Z",
     "shell.execute_reply": "2025-02-02T20:39:18.701146Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.696518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "-------------------------\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(\"-------------------------\")\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.702953Z",
     "iopub.status.busy": "2025-02-02T20:39:18.702639Z",
     "iopub.status.idle": "2025-02-02T20:39:18.714523Z",
     "shell.execute_reply": "2025-02-02T20:39:18.713841Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.702904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_ctc_loss(y_true, y_pred):\n",
    "    batch_size = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_size, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_size, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.715343Z",
     "iopub.status.busy": "2025-02-02T20:39:18.715173Z",
     "iopub.status.idle": "2025-02-02T20:39:18.728939Z",
     "shell.execute_reply": "2025-02-02T20:39:18.728155Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.715327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:18.733086Z",
     "iopub.status.busy": "2025-02-02T20:39:18.732862Z",
     "iopub.status.idle": "2025-02-02T20:39:23.173262Z",
     "shell.execute_reply": "2025-02-02T20:39:23.172258Z",
     "shell.execute_reply.started": "2025-02-02T20:39:18.733056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "lip_model = Sequential()\n",
    "lip_model.add(Input(shape=(75, 60, 140, 1)))  \n",
    "lip_model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "lip_model.add(Activation('relu'))\n",
    "lip_model.add(MaxPool3D((1, 2, 2)))\n",
    "lip_model.add(Conv3D(64, (3, 3, 3), padding='same'))\n",
    "lip_model.add(Activation('relu'))\n",
    "lip_model.add(MaxPool3D((1, 2, 2)))\n",
    "lip_model.add(Conv3D(128, (3, 3, 3), padding='same'))\n",
    "lip_model.add(Activation('relu'))\n",
    "lip_model.add(MaxPool3D((1, 2, 2)))\n",
    "lip_model.add(TimeDistributed(Flatten()))\n",
    "lip_model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "lip_model.add(Dropout(0.5))\n",
    "lip_model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "lip_model.add(Dropout(0.5))\n",
    "lip_model.add(Dense(char_to_index.vocabulary_size() + 1, kernel_initializer='he_normal', activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:23.175171Z",
     "iopub.status.busy": "2025-02-02T20:39:23.174853Z",
     "iopub.status.idle": "2025-02-02T20:39:23.187836Z",
     "shell.execute_reply": "2025-02-02T20:39:23.187191Z",
     "shell.execute_reply.started": "2025-02-02T20:39:23.175140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "lip_model.compile(optimizer=optimizer, loss=custom_ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:23.188812Z",
     "iopub.status.busy": "2025-02-02T20:39:23.188549Z",
     "iopub.status.idle": "2025-02-02T20:39:24.707248Z",
     "shell.execute_reply": "2025-02-02T20:39:24.706481Z",
     "shell.execute_reply.started": "2025-02-02T20:39:23.188792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15232</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">15,729,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,537</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m55,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m221,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m15232\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │      \u001b[38;5;34m15,729,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m394,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m41\u001b[0m)              │          \u001b[38;5;34m10,537\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,412,009</span> (62.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,412,009\u001b[0m (62.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,412,009</span> (62.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,412,009\u001b[0m (62.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lip_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:24.708370Z",
     "iopub.status.busy": "2025-02-02T20:39:24.708006Z",
     "iopub.status.idle": "2025-02-02T20:39:26.666518Z",
     "shell.execute_reply": "2025-02-02T20:39:26.665732Z",
     "shell.execute_reply.started": "2025-02-02T20:39:24.708341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "chek = lip_model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.667863Z",
     "iopub.status.busy": "2025-02-02T20:39:26.667506Z",
     "iopub.status.idle": "2025-02-02T20:39:26.771040Z",
     "shell.execute_reply": "2025-02-02T20:39:26.770325Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.667832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttaaaaaaaaa'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(chek[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.772075Z",
     "iopub.status.busy": "2025-02-02T20:39:26.771858Z",
     "iopub.status.idle": "2025-02-02T20:39:26.776565Z",
     "shell.execute_reply": "2025-02-02T20:39:26.775884Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.772056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 75, 60, 140, 1)\n",
      "Output shape: (None, 75, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", lip_model.input_shape)\n",
    "print(\"Output shape:\", lip_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.777694Z",
     "iopub.status.busy": "2025-02-02T20:39:26.777374Z",
     "iopub.status.idle": "2025-02-02T20:39:26.791079Z",
     "shell.execute_reply": "2025-02-02T20:39:26.790458Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.777646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 25:\n",
    "        return lr  \n",
    "    else:\n",
    "        return float(lr * 0.95)        \n",
    "schedule_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.792314Z",
     "iopub.status.busy": "2025-02-02T20:39:26.791985Z",
     "iopub.status.idle": "2025-02-02T20:39:26.802582Z",
     "shell.execute_reply": "2025-02-02T20:39:26.801902Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.792291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='checkpoint.weights.h5',  \n",
    "    monitor='val_loss',                        \n",
    "    save_best_only=True,                       \n",
    "    save_weights_only=True,                     \n",
    "    verbose=1                                   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.803571Z",
     "iopub.status.busy": "2025-02-02T20:39:26.803330Z",
     "iopub.status.idle": "2025-02-02T20:39:26.820525Z",
     "shell.execute_reply": "2025-02-02T20:39:26.819782Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.803554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_wer(y_true, y_pred, decoder):\n",
    "\n",
    "    wer_scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        true_text = tf.strings.reduce_join(num_to_char(y_true[i])).numpy().decode('utf-8')\n",
    "        decoded = decoder(y_pred[i:i+1])[0]\n",
    "        wer_scores.append(levenshtein_distance(true_text.split(), decoded.split()) / len(true_text.split()))\n",
    "    return np.mean(wer_scores)\n",
    "\n",
    "def ctc_decoder():\n",
    "    def decoder(pred):\n",
    "        input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "        results = tf.keras.backend.ctc_decode(pred, \n",
    "                                            input_length=input_len,\n",
    "                                            greedy=True)[0][0]\n",
    "        texts = []\n",
    "        for res in results:\n",
    "            res = tf.strings.reduce_join(num_to_char(res)).numpy().decode('utf-8')\n",
    "            texts.append(res)\n",
    "        return texts\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.821638Z",
     "iopub.status.busy": "2025-02-02T20:39:26.821326Z",
     "iopub.status.idle": "2025-02-02T20:39:26.832473Z",
     "shell.execute_reply": "2025-02-02T20:39:26.831922Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.821610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PrintLRCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n",
    "        print(f\"Epoch {epoch + 1}: Learning Rate = {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:26.833678Z",
     "iopub.status.busy": "2025-02-02T20:39:26.833390Z",
     "iopub.status.idle": "2025-02-02T20:39:27.082518Z",
     "shell.execute_reply": "2025-02-02T20:39:27.081709Z",
     "shell.execute_reply.started": "2025-02-02T20:39:26.833634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  2 20:39:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   52C    P0             36W /   70W |    1283MiB /  15360MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   55C    P0             29W /   70W |     103MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:27.083796Z",
     "iopub.status.busy": "2025-02-02T20:39:27.083522Z",
     "iopub.status.idle": "2025-02-02T20:39:27.348129Z",
     "shell.execute_reply": "2025-02-02T20:39:27.347212Z",
     "shell.execute_reply.started": "2025-02-02T20:39:27.083774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 75, 60, 140, 1)\n",
      "Output shape: (2, 40)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data.take(1):\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:27.349250Z",
     "iopub.status.busy": "2025-02-02T20:39:27.349025Z",
     "iopub.status.idle": "2025-02-02T20:39:27.353236Z",
     "shell.execute_reply": "2025-02-02T20:39:27.352322Z",
     "shell.execute_reply.started": "2025-02-02T20:39:27.349231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=10,         \n",
    "    restore_best_weights=True,  \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:39:27.354444Z",
     "iopub.status.busy": "2025-02-02T20:39:27.354130Z",
     "iopub.status.idle": "2025-02-02T23:26:17.278600Z",
     "shell.execute_reply": "2025-02-02T23:26:17.277716Z",
     "shell.execute_reply.started": "2025-02-02T20:39:27.354398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 100.6755\n",
      "Epoch 1: val_loss improved from inf to 66.91669, saving model to checkpoint.weights.h5\n",
      "Epoch 1: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 292ms/step - loss: 100.6254 - val_loss: 66.9167 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 69.4772\n",
      "Epoch 2: val_loss improved from 66.91669 to 63.58356, saving model to checkpoint.weights.h5\n",
      "Epoch 2: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 69.4748 - val_loss: 63.5836 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 66.1835\n",
      "Epoch 3: val_loss improved from 63.58356 to 62.23447, saving model to checkpoint.weights.h5\n",
      "Epoch 3: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 290ms/step - loss: 66.1831 - val_loss: 62.2345 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 64.1789\n",
      "Epoch 4: val_loss improved from 62.23447 to 60.19411, saving model to checkpoint.weights.h5\n",
      "Epoch 4: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 292ms/step - loss: 64.1785 - val_loss: 60.1941 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 62.4286\n",
      "Epoch 5: val_loss improved from 60.19411 to 58.99088, saving model to checkpoint.weights.h5\n",
      "Epoch 5: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 290ms/step - loss: 62.4280 - val_loss: 58.9909 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 61.1195\n",
      "Epoch 6: val_loss improved from 58.99088 to 57.53051, saving model to checkpoint.weights.h5\n",
      "Epoch 6: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 61.1189 - val_loss: 57.5305 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 59.5656\n",
      "Epoch 7: val_loss improved from 57.53051 to 49.08504, saving model to checkpoint.weights.h5\n",
      "Epoch 7: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 287ms/step - loss: 59.5619 - val_loss: 49.0850 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 51.0391\n",
      "Epoch 8: val_loss improved from 49.08504 to 48.03744, saving model to checkpoint.weights.h5\n",
      "Epoch 8: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 51.0388 - val_loss: 48.0374 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 49.8899\n",
      "Epoch 9: val_loss improved from 48.03744 to 47.16467, saving model to checkpoint.weights.h5\n",
      "Epoch 9: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - loss: 49.8899 - val_loss: 47.1647 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 49.0824\n",
      "Epoch 10: val_loss improved from 47.16467 to 46.59620, saving model to checkpoint.weights.h5\n",
      "Epoch 10: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 49.0826 - val_loss: 46.5962 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 48.6114\n",
      "Epoch 11: val_loss improved from 46.59620 to 46.05626, saving model to checkpoint.weights.h5\n",
      "Epoch 11: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 48.6114 - val_loss: 46.0563 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 47.9690\n",
      "Epoch 12: val_loss improved from 46.05626 to 45.40001, saving model to checkpoint.weights.h5\n",
      "Epoch 12: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 47.9692 - val_loss: 45.4000 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 47.4295\n",
      "Epoch 13: val_loss improved from 45.40001 to 44.74974, saving model to checkpoint.weights.h5\n",
      "Epoch 13: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - loss: 47.4297 - val_loss: 44.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 47.0698\n",
      "Epoch 14: val_loss improved from 44.74974 to 43.99239, saving model to checkpoint.weights.h5\n",
      "Epoch 14: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - loss: 47.0704 - val_loss: 43.9924 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 46.5208\n",
      "Epoch 15: val_loss improved from 43.99239 to 43.85536, saving model to checkpoint.weights.h5\n",
      "Epoch 15: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - loss: 46.5212 - val_loss: 43.8554 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 46.2755\n",
      "Epoch 16: val_loss improved from 43.85536 to 43.20105, saving model to checkpoint.weights.h5\n",
      "Epoch 16: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 46.2761 - val_loss: 43.2010 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 45.9662\n",
      "Epoch 17: val_loss improved from 43.20105 to 42.76721, saving model to checkpoint.weights.h5\n",
      "Epoch 17: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 45.9662 - val_loss: 42.7672 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 45.6455\n",
      "Epoch 18: val_loss improved from 42.76721 to 42.57657, saving model to checkpoint.weights.h5\n",
      "Epoch 18: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - loss: 45.6454 - val_loss: 42.5766 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 45.0780\n",
      "Epoch 19: val_loss improved from 42.57657 to 42.00125, saving model to checkpoint.weights.h5\n",
      "Epoch 19: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 45.0783 - val_loss: 42.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 44.6315\n",
      "Epoch 20: val_loss improved from 42.00125 to 41.69599, saving model to checkpoint.weights.h5\n",
      "Epoch 20: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 44.6321 - val_loss: 41.6960 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 44.4216\n",
      "Epoch 21: val_loss improved from 41.69599 to 40.84010, saving model to checkpoint.weights.h5\n",
      "Epoch 21: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 44.4218 - val_loss: 40.8401 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 43.8651\n",
      "Epoch 22: val_loss improved from 40.84010 to 40.38187, saving model to checkpoint.weights.h5\n",
      "Epoch 22: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 43.8656 - val_loss: 40.3819 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 43.3584\n",
      "Epoch 23: val_loss improved from 40.38187 to 39.83825, saving model to checkpoint.weights.h5\n",
      "Epoch 23: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 287ms/step - loss: 43.3592 - val_loss: 39.8382 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 42.9515\n",
      "Epoch 24: val_loss did not improve from 39.83825\n",
      "Epoch 24: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 42.9521 - val_loss: 40.2785 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 42.5757\n",
      "Epoch 25: val_loss improved from 39.83825 to 39.70073, saving model to checkpoint.weights.h5\n",
      "Epoch 25: Learning Rate = 9.999999747378752e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 42.5761 - val_loss: 39.7007 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 42.1493\n",
      "Epoch 26: val_loss improved from 39.70073 to 38.84562, saving model to checkpoint.weights.h5\n",
      "Epoch 26: Learning Rate = 9.499999578110874e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 293ms/step - loss: 42.1498 - val_loss: 38.8456 - learning_rate: 9.5000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 41.3859\n",
      "Epoch 27: val_loss improved from 38.84562 to 37.95524, saving model to checkpoint.weights.h5\n",
      "Epoch 27: Learning Rate = 9.02499959920533e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 41.3867 - val_loss: 37.9552 - learning_rate: 9.0250e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 40.8069\n",
      "Epoch 28: val_loss improved from 37.95524 to 37.74694, saving model to checkpoint.weights.h5\n",
      "Epoch 28: Learning Rate = 8.573749801144004e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 40.8078 - val_loss: 37.7469 - learning_rate: 8.5737e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 40.2435\n",
      "Epoch 29: val_loss improved from 37.74694 to 36.81643, saving model to checkpoint.weights.h5\n",
      "Epoch 29: Learning Rate = 8.145062020048499e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 40.2439 - val_loss: 36.8164 - learning_rate: 8.1451e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 39.6245\n",
      "Epoch 30: val_loss improved from 36.81643 to 36.71432, saving model to checkpoint.weights.h5\n",
      "Epoch 30: Learning Rate = 7.737809210084379e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 39.6250 - val_loss: 36.7143 - learning_rate: 7.7378e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 39.1443\n",
      "Epoch 31: val_loss did not improve from 36.71432\n",
      "Epoch 31: Learning Rate = 7.350918895099312e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 39.1447 - val_loss: 36.7322 - learning_rate: 7.3509e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 38.5680\n",
      "Epoch 32: val_loss improved from 36.71432 to 34.70075, saving model to checkpoint.weights.h5\n",
      "Epoch 32: Learning Rate = 6.983373168623075e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 38.5684 - val_loss: 34.7007 - learning_rate: 6.9834e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 38.0389\n",
      "Epoch 33: val_loss improved from 34.70075 to 34.51329, saving model to checkpoint.weights.h5\n",
      "Epoch 33: Learning Rate = 6.634204328292981e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - loss: 38.0390 - val_loss: 34.5133 - learning_rate: 6.6342e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 37.3859\n",
      "Epoch 34: val_loss improved from 34.51329 to 33.92671, saving model to checkpoint.weights.h5\n",
      "Epoch 34: Learning Rate = 6.30249414825812e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 37.3863 - val_loss: 33.9267 - learning_rate: 6.3025e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 36.7680\n",
      "Epoch 35: val_loss improved from 33.92671 to 33.78058, saving model to checkpoint.weights.h5\n",
      "Epoch 35: Learning Rate = 5.98736951360479e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - loss: 36.7684 - val_loss: 33.7806 - learning_rate: 5.9874e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 36.8547\n",
      "Epoch 36: val_loss improved from 33.78058 to 33.63228, saving model to checkpoint.weights.h5\n",
      "Epoch 36: Learning Rate = 5.688000965164974e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 287ms/step - loss: 36.8566 - val_loss: 33.6323 - learning_rate: 5.6880e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 36.4914\n",
      "Epoch 37: val_loss improved from 33.63228 to 32.75042, saving model to checkpoint.weights.h5\n",
      "Epoch 37: Learning Rate = 5.4036008805269375e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 36.4917 - val_loss: 32.7504 - learning_rate: 5.4036e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 35.6707\n",
      "Epoch 38: val_loss improved from 32.75042 to 31.86388, saving model to checkpoint.weights.h5\n",
      "Epoch 38: Learning Rate = 5.133420927450061e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 35.6713 - val_loss: 31.8639 - learning_rate: 5.1334e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 34.8870\n",
      "Epoch 39: val_loss improved from 31.86388 to 31.71833, saving model to checkpoint.weights.h5\n",
      "Epoch 39: Learning Rate = 4.876749881077558e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 34.8878 - val_loss: 31.7183 - learning_rate: 4.8767e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 34.4791\n",
      "Epoch 40: val_loss improved from 31.71833 to 31.29157, saving model to checkpoint.weights.h5\n",
      "Epoch 40: Learning Rate = 4.632912532542832e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 34.4799 - val_loss: 31.2916 - learning_rate: 4.6329e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 34.2858\n",
      "Epoch 41: val_loss improved from 31.29157 to 30.60366, saving model to checkpoint.weights.h5\n",
      "Epoch 41: Learning Rate = 4.401266778586432e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - loss: 34.2860 - val_loss: 30.6037 - learning_rate: 4.4013e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 34.0913\n",
      "Epoch 42: val_loss did not improve from 30.60366\n",
      "Epoch 42: Learning Rate = 4.1812032577581704e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 291ms/step - loss: 34.0907 - val_loss: 30.6205 - learning_rate: 4.1812e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 33.3368\n",
      "Epoch 43: val_loss improved from 30.60366 to 29.13127, saving model to checkpoint.weights.h5\n",
      "Epoch 43: Learning Rate = 3.972143167629838e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 297ms/step - loss: 33.3373 - val_loss: 29.1313 - learning_rate: 3.9721e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 33.0547\n",
      "Epoch 44: val_loss did not improve from 29.13127\n",
      "Epoch 44: Learning Rate = 3.773536082007922e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 33.0544 - val_loss: 29.5070 - learning_rate: 3.7735e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 32.9085\n",
      "Epoch 45: val_loss improved from 29.13127 to 29.04678, saving model to checkpoint.weights.h5\n",
      "Epoch 45: Learning Rate = 3.584859223337844e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 306ms/step - loss: 32.9079 - val_loss: 29.0468 - learning_rate: 3.5849e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 32.4265\n",
      "Epoch 46: val_loss improved from 29.04678 to 28.77127, saving model to checkpoint.weights.h5\n",
      "Epoch 46: Learning Rate = 3.405616371310316e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 291ms/step - loss: 32.4262 - val_loss: 28.7713 - learning_rate: 3.4056e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 31.7555\n",
      "Epoch 47: val_loss improved from 28.77127 to 28.31075, saving model to checkpoint.weights.h5\n",
      "Epoch 47: Learning Rate = 3.2353356800740585e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 31.7548 - val_loss: 28.3107 - learning_rate: 3.2353e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 31.3873\n",
      "Epoch 48: val_loss improved from 28.31075 to 27.74930, saving model to checkpoint.weights.h5\n",
      "Epoch 48: Learning Rate = 3.0735689506400377e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - loss: 31.3873 - val_loss: 27.7493 - learning_rate: 3.0736e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 31.2257\n",
      "Epoch 49: val_loss improved from 27.74930 to 26.90681, saving model to checkpoint.weights.h5\n",
      "Epoch 49: Learning Rate = 2.919890539487824e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 284ms/step - loss: 31.2251 - val_loss: 26.9068 - learning_rate: 2.9199e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 31.0660\n",
      "Epoch 50: val_loss improved from 26.90681 to 26.47817, saving model to checkpoint.weights.h5\n",
      "Epoch 50: Learning Rate = 2.7738960852730088e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 31.0649 - val_loss: 26.4782 - learning_rate: 2.7739e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 30.5495\n",
      "Epoch 51: val_loss did not improve from 26.47817\n",
      "Epoch 51: Learning Rate = 2.6352012355346233e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 278ms/step - loss: 30.5491 - val_loss: 26.6206 - learning_rate: 2.6352e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 30.1857\n",
      "Epoch 52: val_loss improved from 26.47817 to 26.07780, saving model to checkpoint.weights.h5\n",
      "Epoch 52: Learning Rate = 2.503441100998316e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 291ms/step - loss: 30.1851 - val_loss: 26.0778 - learning_rate: 2.5034e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 29.8828\n",
      "Epoch 53: val_loss improved from 26.07780 to 25.68495, saving model to checkpoint.weights.h5\n",
      "Epoch 53: Learning Rate = 2.378268982283771e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 29.8824 - val_loss: 25.6849 - learning_rate: 2.3783e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 29.6058\n",
      "Epoch 54: val_loss improved from 25.68495 to 25.28165, saving model to checkpoint.weights.h5\n",
      "Epoch 54: Learning Rate = 2.2593554604100063e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - loss: 29.6053 - val_loss: 25.2816 - learning_rate: 2.2594e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 29.2415\n",
      "Epoch 55: val_loss improved from 25.28165 to 24.96957, saving model to checkpoint.weights.h5\n",
      "Epoch 55: Learning Rate = 2.146387669199612e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 29.2409 - val_loss: 24.9696 - learning_rate: 2.1464e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 29.0712\n",
      "Epoch 56: val_loss improved from 24.96957 to 24.46304, saving model to checkpoint.weights.h5\n",
      "Epoch 56: Learning Rate = 2.0390682038851082e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 29.0705 - val_loss: 24.4630 - learning_rate: 2.0391e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 28.6976\n",
      "Epoch 57: val_loss improved from 24.46304 to 24.23721, saving model to checkpoint.weights.h5\n",
      "Epoch 57: Learning Rate = 1.9371147573110647e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 284ms/step - loss: 28.6973 - val_loss: 24.2372 - learning_rate: 1.9371e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 28.7357\n",
      "Epoch 58: val_loss improved from 24.23721 to 24.08090, saving model to checkpoint.weights.h5\n",
      "Epoch 58: Learning Rate = 1.8402590285404585e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 28.7346 - val_loss: 24.0809 - learning_rate: 1.8403e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 28.2108\n",
      "Epoch 59: val_loss did not improve from 24.08090\n",
      "Epoch 59: Learning Rate = 1.7482459952589124e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - loss: 28.2104 - val_loss: 24.0864 - learning_rate: 1.7482e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 28.0977\n",
      "Epoch 60: val_loss improved from 24.08090 to 23.44780, saving model to checkpoint.weights.h5\n",
      "Epoch 60: Learning Rate = 1.660833731875755e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 28.0971 - val_loss: 23.4478 - learning_rate: 1.6608e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 27.5251\n",
      "Epoch 61: val_loss did not improve from 23.44780\n",
      "Epoch 61: Learning Rate = 1.5777921362314373e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 278ms/step - loss: 27.5247 - val_loss: 23.6619 - learning_rate: 1.5778e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 27.6976\n",
      "Epoch 62: val_loss improved from 23.44780 to 23.19585, saving model to checkpoint.weights.h5\n",
      "Epoch 62: Learning Rate = 1.4989025657996535e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 292ms/step - loss: 27.6965 - val_loss: 23.1959 - learning_rate: 1.4989e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 27.4044\n",
      "Epoch 63: val_loss improved from 23.19585 to 22.97480, saving model to checkpoint.weights.h5\n",
      "Epoch 63: Learning Rate = 1.423957473889459e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 27.4035 - val_loss: 22.9748 - learning_rate: 1.4240e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 26.9732\n",
      "Epoch 64: val_loss improved from 22.97480 to 22.87057, saving model to checkpoint.weights.h5\n",
      "Epoch 64: Learning Rate = 1.352759591100039e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 287ms/step - loss: 26.9726 - val_loss: 22.8706 - learning_rate: 1.3528e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 26.9917\n",
      "Epoch 65: val_loss improved from 22.87057 to 22.61854, saving model to checkpoint.weights.h5\n",
      "Epoch 65: Learning Rate = 1.2851216524722986e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 26.9911 - val_loss: 22.6185 - learning_rate: 1.2851e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 26.6792\n",
      "Epoch 66: val_loss improved from 22.61854 to 22.27268, saving model to checkpoint.weights.h5\n",
      "Epoch 66: Learning Rate = 1.2208655789436307e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 26.6788 - val_loss: 22.2727 - learning_rate: 1.2209e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 26.9761\n",
      "Epoch 67: val_loss improved from 22.27268 to 22.23584, saving model to checkpoint.weights.h5\n",
      "Epoch 67: Learning Rate = 1.1598222954489756e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 26.9749 - val_loss: 22.2358 - learning_rate: 1.1598e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 26.3684\n",
      "Epoch 68: val_loss improved from 22.23584 to 22.23384, saving model to checkpoint.weights.h5\n",
      "Epoch 68: Learning Rate = 1.1018311852240004e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 26.3677 - val_loss: 22.2338 - learning_rate: 1.1018e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 26.2483\n",
      "Epoch 69: val_loss improved from 22.23384 to 21.88831, saving model to checkpoint.weights.h5\n",
      "Epoch 69: Learning Rate = 1.0467396350577474e-05\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 26.2476 - val_loss: 21.8883 - learning_rate: 1.0467e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 26.1043\n",
      "Epoch 70: val_loss improved from 21.88831 to 21.62163, saving model to checkpoint.weights.h5\n",
      "Epoch 70: Learning Rate = 9.94402671494754e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 26.1040 - val_loss: 21.6216 - learning_rate: 9.9440e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 26.0644\n",
      "Epoch 71: val_loss did not improve from 21.62163\n",
      "Epoch 71: Learning Rate = 9.446825060877018e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 26.0637 - val_loss: 21.8590 - learning_rate: 9.4468e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 25.8941\n",
      "Epoch 72: val_loss improved from 21.62163 to 21.56034, saving model to checkpoint.weights.h5\n",
      "Epoch 72: Learning Rate = 8.974483534984756e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 25.8932 - val_loss: 21.5603 - learning_rate: 8.9745e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 25.8113\n",
      "Epoch 73: val_loss improved from 21.56034 to 21.41435, saving model to checkpoint.weights.h5\n",
      "Epoch 73: Learning Rate = 8.525759767508134e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 25.8104 - val_loss: 21.4144 - learning_rate: 8.5258e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 25.6008\n",
      "Epoch 74: val_loss did not improve from 21.41435\n",
      "Epoch 74: Learning Rate = 8.099471415334847e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 25.6001 - val_loss: 21.6124 - learning_rate: 8.0995e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 25.5968\n",
      "Epoch 75: val_loss improved from 21.41435 to 21.23302, saving model to checkpoint.weights.h5\n",
      "Epoch 75: Learning Rate = 7.69449798099231e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 292ms/step - loss: 25.5960 - val_loss: 21.2330 - learning_rate: 7.6945e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 25.6641\n",
      "Epoch 76: val_loss improved from 21.23302 to 21.20257, saving model to checkpoint.weights.h5\n",
      "Epoch 76: Learning Rate = 7.309773081942694e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 289ms/step - loss: 25.6630 - val_loss: 21.2026 - learning_rate: 7.3098e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 25.1373\n",
      "Epoch 77: val_loss improved from 21.20257 to 20.99539, saving model to checkpoint.weights.h5\n",
      "Epoch 77: Learning Rate = 6.944284450582927e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 25.1369 - val_loss: 20.9954 - learning_rate: 6.9443e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 25.3029\n",
      "Epoch 78: val_loss did not improve from 20.99539\n",
      "Epoch 78: Learning Rate = 6.597070296265883e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 25.3021 - val_loss: 21.4051 - learning_rate: 6.5971e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 25.2670\n",
      "Epoch 79: val_loss did not improve from 20.99539\n",
      "Epoch 79: Learning Rate = 6.267216576816281e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 25.2662 - val_loss: 21.0892 - learning_rate: 6.2672e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 25.4741\n",
      "Epoch 80: val_loss improved from 20.99539 to 20.68848, saving model to checkpoint.weights.h5\n",
      "Epoch 80: Learning Rate = 5.9538556342886295e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 25.4730 - val_loss: 20.6885 - learning_rate: 5.9539e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 25.0251\n",
      "Epoch 81: val_loss did not improve from 20.68848\n",
      "Epoch 81: Learning Rate = 5.656163011735771e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 25.0245 - val_loss: 20.8843 - learning_rate: 5.6562e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 25.0389\n",
      "Epoch 82: val_loss did not improve from 20.68848\n",
      "Epoch 82: Learning Rate = 5.373354724724777e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 25.0378 - val_loss: 20.7165 - learning_rate: 5.3734e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 25.1523\n",
      "Epoch 83: val_loss improved from 20.68848 to 20.46729, saving model to checkpoint.weights.h5\n",
      "Epoch 83: Learning Rate = 5.104686806589598e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - loss: 25.1509 - val_loss: 20.4673 - learning_rate: 5.1047e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 24.5951\n",
      "Epoch 84: val_loss did not improve from 20.46729\n",
      "Epoch 84: Learning Rate = 4.849452579946956e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 24.5945 - val_loss: 20.5919 - learning_rate: 4.8495e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 24.9700\n",
      "Epoch 85: val_loss did not improve from 20.46729\n",
      "Epoch 85: Learning Rate = 4.60697992821224e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 279ms/step - loss: 24.9684 - val_loss: 20.6454 - learning_rate: 4.6070e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 24.7451\n",
      "Epoch 86: val_loss improved from 20.46729 to 20.34982, saving model to checkpoint.weights.h5\n",
      "Epoch 86: Learning Rate = 4.376630840852158e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 24.7443 - val_loss: 20.3498 - learning_rate: 4.3766e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 24.7755\n",
      "Epoch 87: val_loss improved from 20.34982 to 20.25181, saving model to checkpoint.weights.h5\n",
      "Epoch 87: Learning Rate = 4.1577991396479774e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 303ms/step - loss: 24.7745 - val_loss: 20.2518 - learning_rate: 4.1578e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 24.6041\n",
      "Epoch 88: val_loss improved from 20.25181 to 20.20119, saving model to checkpoint.weights.h5\n",
      "Epoch 88: Learning Rate = 3.949909114453476e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - loss: 24.6034 - val_loss: 20.2012 - learning_rate: 3.9499e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 24.4944\n",
      "Epoch 89: val_loss improved from 20.20119 to 20.16631, saving model to checkpoint.weights.h5\n",
      "Epoch 89: Learning Rate = 3.7524137042055372e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 301ms/step - loss: 24.4935 - val_loss: 20.1663 - learning_rate: 3.7524e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 24.7051\n",
      "Epoch 90: val_loss improved from 20.16631 to 20.03940, saving model to checkpoint.weights.h5\n",
      "Epoch 90: Learning Rate = 3.564793132682098e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 24.7041 - val_loss: 20.0394 - learning_rate: 3.5648e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 24.4649\n",
      "Epoch 91: val_loss did not improve from 20.03940\n",
      "Epoch 91: Learning Rate = 3.386553544260096e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 288ms/step - loss: 24.4643 - val_loss: 20.2803 - learning_rate: 3.3866e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 24.6927\n",
      "Epoch 92: val_loss did not improve from 20.03940\n",
      "Epoch 92: Learning Rate = 3.217225867047091e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - loss: 24.6913 - val_loss: 20.0912 - learning_rate: 3.2172e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 24.8023\n",
      "Epoch 93: val_loss improved from 20.03940 to 19.93384, saving model to checkpoint.weights.h5\n",
      "Epoch 93: Learning Rate = 3.0563646760128904e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - loss: 24.8009 - val_loss: 19.9338 - learning_rate: 3.0564e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 24.3743\n",
      "Epoch 94: val_loss improved from 19.93384 to 19.90209, saving model to checkpoint.weights.h5\n",
      "Epoch 94: Learning Rate = 2.9035463740001433e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - loss: 24.3736 - val_loss: 19.9021 - learning_rate: 2.9035e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 24.6389\n",
      "Epoch 95: val_loss improved from 19.90209 to 19.85007, saving model to checkpoint.weights.h5\n",
      "Epoch 95: Learning Rate = 2.758368964350666e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - loss: 24.6378 - val_loss: 19.8501 - learning_rate: 2.7584e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 24.4385\n",
      "Epoch 96: val_loss improved from 19.85007 to 19.84445, saving model to checkpoint.weights.h5\n",
      "Epoch 96: Learning Rate = 2.6204504592897138e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 284ms/step - loss: 24.4377 - val_loss: 19.8444 - learning_rate: 2.6205e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 24.5675\n",
      "Epoch 97: val_loss improved from 19.84445 to 19.79346, saving model to checkpoint.weights.h5\n",
      "Epoch 97: Learning Rate = 2.4894279704312794e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - loss: 24.5665 - val_loss: 19.7935 - learning_rate: 2.4894e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 24.3696\n",
      "Epoch 98: val_loss improved from 19.79346 to 19.72639, saving model to checkpoint.weights.h5\n",
      "Epoch 98: Learning Rate = 2.3649565719097154e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 284ms/step - loss: 24.3689 - val_loss: 19.7264 - learning_rate: 2.3650e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 24.3239\n",
      "Epoch 99: val_loss did not improve from 19.72639\n",
      "Epoch 99: Learning Rate = 2.2467088456323836e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - loss: 24.3235 - val_loss: 19.7872 - learning_rate: 2.2467e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 24.4183\n",
      "Epoch 100: val_loss improved from 19.72639 to 19.72013, saving model to checkpoint.weights.h5\n",
      "Epoch 100: Learning Rate = 2.134373517037602e-06\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 285ms/step - loss: 24.4177 - val_loss: 19.7201 - learning_rate: 2.1344e-06\n",
      "Restoring model weights from the end of the best epoch: 100.\n"
     ]
    }
   ],
   "source": [
    "history = lip_model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=100,\n",
    "    \n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        schedule_callback,\n",
    "        PrintLRCallback(),\n",
    "        early_stopping,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:26:17.280021Z",
     "iopub.status.busy": "2025-02-02T23:26:17.279700Z",
     "iopub.status.idle": "2025-02-02T23:26:17.285029Z",
     "shell.execute_reply": "2025-02-02T23:26:17.284318Z",
     "shell.execute_reply.started": "2025-02-02T23:26:17.279989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_cer(y_true, y_pred, decoder):\n",
    "    cer_scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        true_text = tf.strings.reduce_join(num_to_char(y_true[i])).numpy().decode('utf-8')\n",
    "        decoded = decoder(y_pred[i:i+1])[0]\n",
    "        cer_scores.append(levenshtein_distance(true_text, decoded) / len(true_text))\n",
    "    return np.mean(cer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:26:17.285941Z",
     "iopub.status.busy": "2025-02-02T23:26:17.285720Z",
     "iopub.status.idle": "2025-02-02T23:26:55.169383Z",
     "shell.execute_reply": "2025-02-02T23:26:55.168528Z",
     "shell.execute_reply.started": "2025-02-02T23:26:17.285922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Character Error Rate (CER): 0.2634\n"
     ]
    }
   ],
   "source": [
    "decoder = ctc_decoder()\n",
    "\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for x_batch, y_batch in test_data:\n",
    "    preds = lip_model.predict(x_batch)\n",
    "    y_true_list.append(y_batch.numpy())\n",
    "    y_pred_list.append(preds)\n",
    "\n",
    "y_true_all = np.concatenate(y_true_list, axis=0)\n",
    "y_pred_all = np.concatenate(y_pred_list, axis=0)\n",
    "\n",
    "cer_score = calculate_cer(y_true_all, y_pred_all, decoder)\n",
    "print(f\"Character Error Rate (CER): {cer_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:28:37.940742Z",
     "iopub.status.busy": "2025-02-02T23:28:37.940385Z",
     "iopub.status.idle": "2025-02-02T23:28:37.945596Z",
     "shell.execute_reply": "2025-02-02T23:28:37.944751Z",
     "shell.execute_reply.started": "2025-02-02T23:28:37.940715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcy : 0.7366\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accurcy : {1.0- cer_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. predict the model on batch and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:29:12.814439Z",
     "iopub.status.busy": "2025-02-02T23:29:12.814140Z",
     "iopub.status.idle": "2025-02-02T23:29:12.984494Z",
     "shell.execute_reply": "2025-02-02T23:29:12.983547Z",
     "shell.execute_reply.started": "2025-02-02T23:29:12.814415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lip_model.load_weights('/kaggle/working/checkpoint.weights.h5')\n",
    "test_data_n = test_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:55:21.946805Z",
     "iopub.status.busy": "2025-02-02T23:55:21.946468Z",
     "iopub.status.idle": "2025-02-02T23:55:21.952265Z",
     "shell.execute_reply": "2025-02-02T23:55:21.951340Z",
     "shell.execute_reply.started": "2025-02-02T23:55:21.946781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ex = test_data_n.next()\n",
    "inputs_batch, targets_batch = ex[0], ex[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:55:40.861577Z",
     "iopub.status.busy": "2025-02-02T23:55:40.861292Z",
     "iopub.status.idle": "2025-02-02T23:55:40.983786Z",
     "shell.execute_reply": "2025-02-02T23:55:40.982966Z",
     "shell.execute_reply.started": "2025-02-02T23:55:40.861555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = lip_model.predict(inputs_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:56:49.919226Z",
     "iopub.status.busy": "2025-02-02T23:56:49.918911Z",
     "iopub.status.idle": "2025-02-02T23:56:49.986740Z",
     "shell.execute_reply": "2025-02-02T23:56:49.985913Z",
     "shell.execute_reply.started": "2025-02-02T23:56:49.919200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------sam----------------------\n",
      "real\n",
      "setwhitewithcsixplease\n",
      "setgreenbyvninesoon\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------sam----------------------\")\n",
    "print(\"real\")\n",
    "for target_seq in targets_batch:\n",
    "    decoded_target = tf.strings.reduce_join([num_to_char(idx) for idx in target_seq])\n",
    "    print(decoded_target.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:57:05.352326Z",
     "iopub.status.busy": "2025-02-02T23:57:05.352058Z",
     "iopub.status.idle": "2025-02-02T23:57:05.361051Z",
     "shell.execute_reply": "2025-02-02T23:57:05.360226Z",
     "shell.execute_reply.started": "2025-02-02T23:57:05.352306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoded_batch, _ = tf.keras.backend.ctc_decode(batch_predictions, input_length=[75, 75], greedy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:57:40.503691Z",
     "iopub.status.busy": "2025-02-02T23:57:40.503375Z",
     "iopub.status.idle": "2025-02-02T23:57:40.633144Z",
     "shell.execute_reply": "2025-02-02T23:57:40.632502Z",
     "shell.execute_reply.started": "2025-02-02T23:57:40.503645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------sam----------------------\n",
      "pred\n",
      "setwhitewithssiplease\n",
      "setredbsineoon\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------sam----------------------\")\n",
    "print(\"pred\")\n",
    "for seq in decoded_batch[0]:\n",
    "    decoded_chars = [num_to_char(idx) for idx in seq if idx != -1]\n",
    "    decoded_string = tf.strings.reduce_join(decoded_chars)\n",
    "    print(decoded_string.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:58:03.972306Z",
     "iopub.status.busy": "2025-02-02T23:58:03.971975Z",
     "iopub.status.idle": "2025-02-02T23:58:04.012525Z",
     "shell.execute_reply": "2025-02-02T23:58:04.011901Z",
     "shell.execute_reply.started": "2025-02-02T23:58:03.972280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "exx = load_lip_data_with_augmentation(tf.convert_to_tensor('/kaggle/working/lip_data/data/s1/bbaf2n.mpg'))\n",
    "video_input, video_target = exx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:58:33.667372Z",
     "iopub.status.busy": "2025-02-02T23:58:33.666942Z",
     "iopub.status.idle": "2025-02-02T23:58:33.695562Z",
     "shell.execute_reply": "2025-02-02T23:58:33.694732Z",
     "shell.execute_reply.started": "2025-02-02T23:58:33.667332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------sam----------------------\n",
      "real\n",
      "binblueatftwonow\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------sam----------------------\")\n",
    "print(\"real\")\n",
    "decoded_video_target = tf.strings.reduce_join([num_to_char(idx) for idx in video_target])\n",
    "print(decoded_video_target.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:59:02.428378Z",
     "iopub.status.busy": "2025-02-02T23:59:02.428053Z",
     "iopub.status.idle": "2025-02-02T23:59:02.524060Z",
     "shell.execute_reply": "2025-02-02T23:59:02.523410Z",
     "shell.execute_reply.started": "2025-02-02T23:59:02.428350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    }
   ],
   "source": [
    "video_input_batch = np.expand_dims(video_input, axis=0)\n",
    "video_pred = lip_model.predict(video_input_batch)\n",
    "decoded_video, _ = tf.keras.backend.ctc_decode(video_pred, input_length=[75], greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:59:17.868126Z",
     "iopub.status.busy": "2025-02-02T23:59:17.867845Z",
     "iopub.status.idle": "2025-02-02T23:59:17.908339Z",
     "shell.execute_reply": "2025-02-02T23:59:17.907690Z",
     "shell.execute_reply.started": "2025-02-02T23:59:17.868096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------sam----------------------\n",
      "pred\n",
      "biyblueitwonow\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------sam----------------------\")\n",
    "print(\"pred\")\n",
    "decoded_video_seq = decoded_video[0][0].numpy()\n",
    "decoded_video_chars = [num_to_char(idx) for idx in decoded_video_seq if idx != -1]\n",
    "decoded_video_text = tf.strings.reduce_join(decoded_video_chars)\n",
    "decoded_str = decoded_video_text.numpy().decode(\"utf-8\")\n",
    "print(decoded_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T23:59:33.068812Z",
     "iopub.status.busy": "2025-02-02T23:59:33.068422Z",
     "iopub.status.idle": "2025-02-02T23:59:33.073696Z",
     "shell.execute_reply": "2025-02-02T23:59:33.072859Z",
     "shell.execute_reply.started": "2025-02-02T23:59:33.068773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented Predicted Text:\n",
      "bi y blue i two now\n"
     ]
    }
   ],
   "source": [
    "segmented_output = \" \".join(wordninja.split(decoded_str))\n",
    "print(\"Segmented Predicted Text:\")\n",
    "print(segmented_output)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
